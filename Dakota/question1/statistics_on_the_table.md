## Statistics on the Table: The History of Statistical Concepts and Methods

**Keywords**: Statistics; History

**Authors**: Stephen M. Stigler

**Date of Publication**: 2002

**Reference**: Stigler, S. M. (2002). Statistics on the Table: The History of Statistical Concepts and Methods (1st edition). Cambridge, Mass.: Harvard University Press.



#### Key Concepts
----

N/A

#### Questions
----

***What is the main argument of the text?***

This text constitutes a collection of essays written about the history of statistics and ideas within statistics, covering such topics as maximum likelihood estimation, degrees of freedom, and regression, while examining such figures as Galton, Pearson, Bayes, and Gauss. As stated in the introduction, "each of these essay is intended to shed light on some corner of the history of statistics, to describe aspects of the subject that will help readers better appreciate the complex whole. Instead of the traditional summary and response to questions, I provide below a brief description of each of the chapters included as part of our reading:

---

*Chapter 1: Karl Pearson and he Cambridge Economists*

In this first chapter, Stigler explores a constroversy instigated by Karl Pearson, a renowned statistician of the early 1900's who was also a key proponent of eugenics and someone who loved to pick fights. This chapter in particular follows Pearson and his ideas as he conducted a study of the affect of parental alcoholism on children. Pearson originally chose this topic in order to show the lack of evidence for the temperence movement, to chip away at the idea that *nurture* was stronger than *nature*, and in so doing support the eugenics movement. Indeed, Pearson found that parental alcoholism had little bearing on the pysical and mental outcomes of their children, and he did so with a reasonable amount of statistical rigor and caution. However, many came out to argue against Pearson, citing potential problems in the data collection and interpretation of the outcomes; many of these criticisms came from those in the temperence movement, as well as some notable economists. Pearson ultimately seemed to come out on top of this debate, and the episode demonstrated the many issues of the use of statistics in public policy. When entering public policy debates with powerful emotional appeal, statisticians will be "challenged on the basis of the limitations of their data, on the basis of a theoretical argument[...], and on the basis that their conclusions run counter to prior beliefs" (pg 47). Still, Pearson wasn't entirely in the clear. Most of his findings were negative, meaninig lack of statistical evidence of an effect, all except for the effect of drinking during pregnancy and associated detrimental effects to children. In his study, Pearson downplayed this effect, arguing that the effect was marginal and trivial, however this effect would later be found to be far more significant, and be termed "fetal alcohol syndrome". 

---

*Chapter 6: Galton and Identificaiton by Fingerprings*

This short chapter discusses Galton's work on the statistical properties of fingerprints and their utility for identification. Fingerprings have many kinds of patterns, large and small, yet Galton argued that it was in the *minutia* of fingerprings that identification was possible. Galton took it as his goal to attempt "to approase the evidential value of finger prints by the common laws of Probability". Galton proved successful, citing a 1 in 64 billion chance of *misidentification*. Following Galton's work, fingerprints enjoyed (and still enjoy) a long history of use in forensic science. However, Stigler argues that in the 1920s, the widespread adoption of fingerprints as evidence was due to (i) their striking visual appearence in court; (ii) a few dramatically successful cases; and (iii) a long period in which they were used without a single case being noted wherein two people's fingerprints echibited the same pattern.

---

*Chapter 7: Stochastic Simulation in the Nineteenth Century*

This chapter examines several kinds of simluations used as a tool in the scientific study of statistics. Stigler examines three simulation devices. In one example, a mathematician named De Forest drew labeled cards from a box, and used these cards to generate random numbers. In anotehr, Darwin (the son of Charles Darwin) created a kind of spinner, with which he would spin a circular card and generate values. Francic Galton, however, preferred the use of dice (he submitted an entire article to Nature about simulation via dice). He would use a series of dice, one that was used to lookup a value in a table and select a range of seed numbers, another to select a much finer scale number (say decimals), and a third to attach signs of positive or negative to the values. None of these schemes were widely adopted, but they demonstrate the differnet ways in which simulation was thought about and adopted within the statistical community. 

---

*Chapter 8: The History of Statistics in 1933*

This chapter investigates the birth of statistics as a discipline, which Stigler places at 1933. This year is a rough estimate, and the year when the American Statistical Association cut its affiliation with the mathematical sciences. Stigler also notes that this is when he claims that the discipline of statistics was founded, not when any key concept was discovered or published. This is also about the time that statistics was of growing importance in industry and military, and when new and more robust methods were necessary. Stigler spends the latter part of this chapter discussing a publication by a social scientist named Secrist who published an ambitious book on the nature of businesses. However, despite its ambitions, this text was criticized by Hotelling as demonstrating a very crucial statistical flaw that rendered its arguments moot. Stigler states that the "major lesson [of this event] is that good statistics requires a conversation between scientists and mathematical statisticians." (pg 170), especially given the many subleties that can affect statistical analyses.

---

*Chapter 9: Regression toward the Mean*

This chapter discusses, as per its title, regression towards the mean. This concept basically means that, given an event that is above or below the mean of a distribution, the next iteration of the event is likely to be *closer* to the mean. The intuition is that an event is subject, at least in part, to some amount of chance. Being exceptionally above or below the distribution is an artefact of chance. However, this chance will likely not effect the next iteration of that event. The common example is a student who does exceptionally well no the first test in the class. This student will be likely to perform *less* well on the second test (closer to the mean). This is because, during the first test, the student likely obtained their score through some combination of ability and luck. In the second test, the ability may remain, but the luck likely won't, and thus the student is likely to get a lower grade. 

Galton was immensely interested in this idea, especially as it related to heretibility of talent. Galton was interested in why the children of talented people were so often not as talented or exceptional as their parents. The truth is, as Galton found, is that children are likely to be more mediocre than their parents. Galton also invented a kind of simulation in which to test this, which was sort of a Plinko machine wherein a ball was dropped and bounced off pegs (see pg 178 for details). 

Stigler also spends several pages discussing the subleties and traps of regression towards the mean. He ultimately states that "the recurrence of regression fallacies is testimony to its subtlety, deceptive simplicity, and, I speculate, t the wide use of the word regression to describe least squares fitting of curves" (pg 186)

*Chapter 10: Statistical Concepts in Psychology*

This chapter discusses why Psychology was so receptive to the use of statistics, while other disciplines like Economics were not, and only adopted widespread use of statistics later. This chapter also discusses why Astronomy adopted statistics so much earlier, by almost a century, than either of these disciplines. 

Astronomy rested on the assumption that, while individual measurements disagreed, there was some objective truth, some latent value that they were studying. The goal of astronomy was thus to solve the equation of *observation = truth + error*. Psycholgy, on the other hand, had no such adherence to this idea of "truth". However, Psychology soon turned to randomized controlled experiments, where a control group would establish a baseline to compare against. This allowed psychologists to sharpen their hypotheses and ask limited but statistically answerable questions. Economics, on the other hand, relied necessarily on observational data and thus could had to push statistical techniques further (eventually to multivariate statistics) in order to make good use of the.

The chapter closes with a good quote:
 
"The role of statistics in the social sciences is thus fundamentally different than its role in much of physical science, in that it creates and defines the objects of study much more directly. Those objects are no less real than those of physical science. They are even often much better understood. But despite the unity of statistics—the smae methods are useful in all areas—there are fundamental differences, and these have played a role in the historical development of all these fields" (pg 199)


*Chapter 14: Stigler's Law of Eponymy*

Here, Stigler discusses the **Stigler Law of Eponymy*, which states that "no scientific discovery is named after its original discoverer", which aptly applies to the the law itself. In this chapter, Stigler discusses the naming and attribution of advances in statistics. Stigler followes discussions earlier by Robert Merton in stating that names are not given by historians of science or even individual scientists, but insteadby communities of practicing scientists. Moreover, names are rarely given and never generally accepted unless the name is remote in time or place (or both) from the scientist being honored. In simpler terms, Stigler claims that "...eponyms are only awarded after long time lags or at great distances, and then only by active (and frequently, not historically well informed) scientists with more interest in recognizing general meric than an isolated achievement" (pg 283-284). Stigler follows his definintion with a quantitative demonstration (in the style of Merton) by counting the eponyms ascribed to a statistical discovery in over 80 textbooks from several countries.

---

These last two chapters of the reading aren't really as interesting. They cover specific events (case studies?) in the history of statistics, but I feel are only interesting if you are "in the know". I 

*Chapter 15: Who Discovered Bayes Theorem*

Given Stigler's law of eponyms, it follows that Bayes Theorem was not actually discovered by Thomas Bayes. Using this as a starting point, Stigler embarks on a short foray into the history of Bayes Theorem and the profession affiliations and connections of Thomas Bayes. In doing so, Stigler finds evidence that Thomas Bayes was in fact not the originator of Bayes Theorem, and that instead, another professor named Nicholas Saunderson was the originator. Stigler tallies the evidence for these two individuals and finds that there is ample evidence for both, and that more research is necessary to determine who exactly discovered Bayes Theorem. 

---

*Chapter 19: Karl Pearson and Degrees of Freedom*

In this chapter, Stigler discisses another case study focusing on Karl Pearson. This time, the focus is on Pearson's development of contingency tables and in particular, of his use of degrees of freedom. Pearson pushed the techniques for studying independence and contingency tables when studying, what else, but eugenics. Stigler follows the evolution of Pearson's thoughts on degrees of freedom and error from 1900 to around 1913 and beyond. When Pearson developed contingency tables, he lacked the discovery that would eventually necessitate degrees of freedom and Fisher's correction. However, still in his early work, Pearon displayed a quality of mind in thinking about and modelling his data. 
 


#### Relevance to my research
----


#### Other Notes
----
