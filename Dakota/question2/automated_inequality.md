## Automated Inequality: How HIgh-Tech Tools Profile, Police, and Punish the Poor

**Keywords**:  Data Science; Machine Learning; Machine Bias; Public Policy

**Authors**: Virginia Eubanks

**Date of Publication**: 2018

**Reference**: Eubanks, V. (2018). Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor. New York, NY: St. Martin’s Press.


#### Key Concepts
----

1. **Digital Poorhouse:** Eubanks discusses the "poorhouse" of old—an organization often found in every town that would feed and shelter the poor, but under conditions so terrible that the poorhouse would end up killing many of its residents; this poorhouse was set up not to help the poor, but to punish them—to give the wealthy a sense of having helped, but in reality by punishing the poor and directing them away from public services. Eubanks argues that new technological tools are creating a "digital poorhouse", one that can act more quickly, at greater scale and with actions that can be hidden by greater complexity than the physical poorhouses that policed, profiled and punished previous generations. 

----


***What is the main argument of the text?***

Eubanks argues that automated tools in the area of public services are creating a "digital poorhouse"—a system that surveils the poor, links criminal and social service data, and deals out automated punishments for minor infractions. This digital poorhouse limits the life chances of the poor and their families while allowing the wealthy to disavow responsibility. In this book, Eubanks shows how beliefs in America about the poor come to be infused within the new technologies being used to make decisions. Even when designed with the best of decisions, autoamted systems can still contribute to the digital poorhouse. In her conclusiins, Eubanks argues that good intentions are not enough, and that there is need for more careful and consdierate use of technolgoy, and that there needs to be a sort of Data Science and Software Development "Hippocratic Oath" and principals of "do no harm". She argues that system designers should be more aware of how their systems affect the lives of individuals.

***Describe at least three ways that the main argument is supported.***

Eubanks supports her arguments via three case studies, each of which highlight how technology is being used, in different situations, to punish or disadvantage the poor and to create. "digital poorhouse".

1. The first case study concerns the homeless population in Los Angeles. Here, a system was designed to identify those homeless individuals who were in most need, or who might most benefit from housing. The system was created in hopes of enacting cost-benefit triage to direct LA's limited housing resources to those who needed it most. Reosurces ended up going to the worst-off (those who were in dire situations) or the "best off", those who might just need a small push to get back on their feet; however, this system left vast swathes of the "middle" without help. Eubanks uses this chapter to discuss how the interview questions used in this homeless-to-housing system are deeply personal, could be used by the police to track or surveil the homeless, and make false assumptions about the homeless by attempting to identify the most "deserving" rather than providing broad help. 
2. The second case study concerns an autoamted enrollmenet and eligibility system for Healthcare in Indiana, which was designed by IBM in the hopes of being more efficient than the current human-operated system. However, this system turned what was already a difficult process into an intransigent and impossible one. Any minor error, such as a lack of a signiature or miss-filled form would return a "Failure to Comply" error without any further details, and many people were automatically kicked off of their healthcare with little recourse, and flat out deny the very sick. Moreover, rather than reducing the workload on social workers, they became more swamped with applicatns showing up to their offices concerning system errors; it also forced more people into libraries to seek help with the electronic process. Despites these issues, the system ultiamtely achieved its goal of getting people off of public services, though this was achieved by punishing the poor, rather than helping them.
3. The last case study is about a risk assessment system implemented in Allegheny Country (Pittsburgh) which was intended to help the Child Protection Services make decisions about the risk posed to children in their current situations. This system was interesting because it was designed with a great deal of input from many stakeholders, and was considered a "model" for other similar systems. Caseworkers would input the details of a child's situation and be returned with a score, which caseworkers could consdier, along with the other evidence, when making a decision. However, Eubanks shows that this system is not without its problems—it gave high-risk scores to families to used social services and generated racially-biased results because people were more likely to call Child Services on black families. Moreover, the system also used historical data about an individual to make decisions, which ended up "punishing" families who themselves came from abusive or negligent households. This model was fairly benign, but it shows that even with careful and thoughtoful design, that there are still issues and dangers in the use of AI to target the poor. 

***Describe the main literatures that the text draws on and contributes to, and the particular contribution made by the text.***

The text largely consists of a couple of case studies, each the product of Eubanks’ personal investigation, which she then pulls together to argue and advocate for a different relationship with technology and poverty. She does not draw on extensive historical research (save for her chapter on the "Digital Poorhouse") nor does she cite many theoretical pieces. 

This book contributes to the ongoing discussions on algortihmic bias and fairness. It also contributes to the conversations about poverty in the United States and beyond—a conversation in which technology be becoming increasingly relevant. 


***Describe the methodology (or methodologies) used in the text, and how it enables the author(s) to support the text’s main argument.***

The methodology is a mix of interviews, personal accounts, and archival research. She analyzes the stories of individuals, and uses statistics and documents to back up claims as needed. One interesting piece of evidence that she adds is the text that people receive when they were denied service. She also pulls from court transcripts and other legal documents.


This text is equal part scholarly analysis and advocacy. By using an abundance of personal accounts, Eubanks is able to tell compelling stories and posit a moral element to all of her arguments. Published and archival research is used more rarely, almost as peripheral support to the main substance of the book, which is advocacy through personal stories and examples. 

***What quotes capture the critical significance of the text?***

1. *“The goals of the project were consistent throughout the automation experiment: maximize efficiency and eliminate fraud by shifting to a task-based system and severing caseworker-to-client bonds. They were clearly reflected in contract metrics: response time in the coll centers was a key performance indicator; determination accuracy was not. Efficiency and savings were built into the contract; transparency and due process were not.”* (pg 74)

2. *“The digital poorhouse denies access to shared resources. It asks invasive and traumatizing questions. It makes it difficult to understand how government bureaucracy works, who has access to your information, and how they use it. It teaches us that we only belong in political community if we are perfect: never leave an “I” uncrossed, never forget an appointment, never make a mistake. It offers paltry carrots: 15 minutes with a county psychologist, a few dollars cash, a short at rental assistance. It wields an enormous stick: child removal, loss of healthcare, incarceration. The digital poorhouse is a “gotcha” system of governance, an invisible bully with a lethally fast punch.”* (pg 197)

3. *“At lectures, conferences, and gatherings, I am often approached by engineers or data scientists who want to talk about the economic and social implications of their designs. I tell them to do a quick “gut check” by answering two questions
Does the tool increase the self-determination and agency of the poor?
Would the tool be tolerated it it was targeted at non-poor people?
Not one of the technologies I describe in this book rises to this feeble standard. We must demand more.”* (pg 211 - 212)


#### Relevance to my research
----

This book shows how automated systems can perpetuate inequality and punish the poor. However, I am unsure of the extent to which the "technology" is to blame compared to poor or malicious governance. I think this is a wider problem with much of this literature: how much blame to we put on technology and those who created it as compared to the policy makers who demanded and continue to use it? For example, IBM helped make the autoamted enrollmenet system for Medicare, but the Indiana Govrenment was the original client who requested it and who set the outcome of "reducing the number of people on social service". 

I think this book is also relevant in showing how, even under the best intentions and design practices, that biases and issues can still emerge in how an autoamted system interacts with the lives of the poor and the workers. 

#### Other Notes
----



