---
tags: [quals]
title: Algorithms of oppression
created: '2020-11-02T00:40:54.841Z'
modified: '2020-11-02T00:41:04.438Z'
---

## Algorithms of oppression: How Search Engines Reinforce Racism

#### Authors: Safiya Umoja Noble
#### Date of Publlication: 2018

#### *Citation*
Noble, S. U. (2018). Algorithms of oppression: How Search Engines Reinforce Racism. New York University Press.

### Concepts

Technological redlinning: forms of racial profiling carried out through the behavior of algorithmic search behaviors and user-tracking. 

#### Descriptive Summary

Noble is interested in the reasons for and consequences of bias in search engines, particularly Google's that reinforce racism. Her research was prompted initally by the observation that Google searches of "black girls" and what should be other innocuous searches about people of color yield racist results that inappropriately contain porn etc. At the first identificaiton of these issues, the silicon valley response has been to characterize these as "glitches" but Noble argues that the "glitch" framework minimizes the wyas that racism is baked into search behavior (the 'glitches' actually represent a racist underlying architecture of search), and is an attempt to absolve silicon valley of responsibility for these racist results. Noble is another of the STS set who are joined on a mission to unpack and dismantle the common and deleterious assumption that technologies--search technologies in Noble's argument--are benign, neutral, and/or objective. They're not.
yes, racist results in search are reflective of racist social attitudes, but the stakes are higher since these kinds of results also inform the ideas of the users who rely on their information. In this way, Noble frames search as mutually constiuitive with society (like Wacjman). Furthermore, the fact that these search engines are commercial let corportae interest put a thumb on the scale in some harmful ways, that wind up prioritizing racist results. 
Noble identifies some of the reasons for the oversights that allowed this to occur, (chief amongst which is the overwhelming whiteness of the workforce in silicon valley who do not represent their users). However, the more structural issue is that the very nature of commercial search will necessarily prioritise the results that are most desirable to the players with the most money--the advertisers and the porn industry (for example), and by prioritising commercial searches, Google's entire business model is set up in ways that make racist and sexist presentations women and black women in particular as more profitable for Google. She joins calls to break up and regulate monopolistic tech companies like google "because their consolidated power and cultural influence make competition largely impossible. 
Noble also has an excellent discussion of the ways that people of color and women are represented and classified within library information systems and other classification systems. Good connection to Bowker and star.
Noble argues most convincingly that the stakes for accurate, not-racist internet search are higher BECAUSE these forms of search are replacing the role of structuring and guiding user inquiries that dedicated professionals like Librarians used to fill. While figures like librarians would have provided accuracy and context to queries, commercial search does not question the framings of the queries, and provide only results that already reflect the (sometimes racist) framings of the user questions and which prioritise commercially profitable results--All while appearing neutral.
The appearance of neutrality and objectivity when the results are racist is an existential danger that Noble identifies-- particularly in the chapter about how Dylan Roof looked for and found info to base his racism on. 

## Chapter summaries

1. A Society, Searching
What appears in the searchers... racist results. 
"Search is a symbiotic process that both informs and is informed by its users" so search technology is mutually constituitive a la Wacjman, since searches society makes informs the results, but also the results inform social attitudes. 
has an eye on the ways that racism and sexism are profitable undercapitalism

2. Searching for Black Girls
Why these types of results are pushed to the front in a commercially based search engine. Reduces subjects of search to whatever is saleable about their bodies-->pornography. ugh--> porn industry has enough money to game search results by taking over keywords of anything that might be a profitable porn search. why searches for just women without porn keyword still gives porn results. 
coming from this, there's some fascinating discussion of the politics of PageRank--> most frequent results are seen by algorithm as truer and more useful. because the algoritms are about predicting what the user wants OVER what the user actually needs. even first authors of PageRank were aware that the algorithm is vulnerable to commercial gaming

cites Wacjman (along with Anna Everett):"each of their projfext points to the specific ways in which technoligical practices priotize the interests of men and whites. for wajcman, 'people and articlacts co-evolve, reminding us that things foulc be otherwise hthat technologies are not the inevitable result of the application of scientific and technical knowledges... the capacity of women users to produce new, advantageous readings of artefacts is dependent upon the broader economic and social circumstances,'"

3. Searching for People and commnities
biggest takeaway for me is the demonstration that because Google caters to what it thinks its users want, the results will necessarily reflect the framing of the queries. for example, racist queries like "black on white crime" will yield exactly the kinds of racist results that reinforce the user's assumptions, particularly dangerous because of the sheen of objective neutrality endemic to these search algoritms lend to their results. Little chance of intervention in the degeneration into racist consipiracy theory etc. in the way that nonprofit information stewards like librarians would provide. 

4. searching for protections from search engines
This is also the right to be forgotten chapter. Connection to boyd and context collapse. Mitigating potential for context collapse is not profitable. 

5. The future of knowledge in the public
critique of information studies and applies work with commercial search to the nonprofit world of information systems, which also need to work on their issues with bias and white-euro centricism. 
Very much about classification systems connection to Bowker and star

6. the future of information culture
public policy recommendations and what good searching would look like: 

conclusion: algorithms of oppression 
a vinginette about a black women who owns and runs a salon trying to navigate the commercial search architecutre of Yelp--it deprioritises her results because a) she does not pay for "premium access" and b) yelp controls the interface and can put competitor informaiton over her page when users search for it. 